# SPDX-License-Identifier: GPL-3.0+
# Parallel download implementation for faster downloads

import threading
import queue
import os
from typing import Callable, Optional
from tqdm import tqdm


class ParallelDownloader:
    """Download a file in parallel using multiple threads/connections."""
    
    def __init__(self, num_threads: int = 4, chunk_size: int = 8 * 1024 * 1024):
        """
        Initialize parallel downloader.
        
        Args:
            num_threads: Number of parallel download threads (default: 4)
            chunk_size: Size of each chunk in bytes (default: 8MB)
        """
        self.num_threads = num_threads
        self.chunk_size = chunk_size
        self.error = None
        self.lock = threading.Lock()
    
    def download(self, 
                 download_func: Callable[[int, int], bytes],
                 output_file: str,
                 total_size: int,
                 start_offset: int = 0,
                 progress_callback: Optional[Callable[[int], None]] = None,
                 log_callback: Optional[Callable[[str], None]] = None) -> bool:
        """
        Download a file in parallel.
        
        Args:
            download_func: Function that takes (start_byte, end_byte) and returns chunk data
            output_file: Path to output file
            total_size: Total size of file to download
            start_offset: Offset to resume from (default: 0)
            progress_callback: Optional callback for progress updates
            log_callback: Optional callback for logging
            
        Returns:
            True if successful, False otherwise
        """
        if start_offset >= total_size:
            return True  # Already downloaded
        
        # Calculate ranges for each thread
        remaining_size = total_size - start_offset
        ranges = []
        
        # Divide the file into segments for parallel download
        segment_size = remaining_size // self.num_threads
        
        for i in range(self.num_threads):
            range_start = start_offset + i * segment_size
            
            # Last thread gets any remaining bytes
            if i == self.num_threads - 1:
                range_end = total_size - 1
            else:
                range_end = range_start + segment_size - 1
            
            if range_start < total_size:
                ranges.append((i, range_start, range_end))
        
        if log_callback:
            log_callback(f"Starting parallel download with {len(ranges)} threads")
        
        # Create a temporary file for each thread
        temp_files = {}
        for thread_id, _, _ in ranges:
            temp_files[thread_id] = f"{output_file}.part{thread_id}"
        
        # Queue for work items
        work_queue = queue.Queue()
        for item in ranges:
            work_queue.put(item)
        
        # Progress tracking
        downloaded_bytes = [0] * len(ranges)
        progress_lock = threading.Lock()
        
        def worker(worker_id: int):
            """Worker thread function."""
            try:
                while not work_queue.empty():
                    try:
                        thread_id, start, end = work_queue.get_nowait()
                    except queue.Empty:
                        break
                    
                    try:
                        # Download the chunk
                        chunk_data = download_func(start, end)
                        
                        # Write to temporary file
                        with open(temp_files[thread_id], 'wb') as f:
                            f.write(chunk_data)
                        
                        # Update progress
                        with progress_lock:
                            downloaded_bytes[thread_id] = len(chunk_data)
                            if progress_callback:
                                progress_callback(len(chunk_data))
                        
                    except Exception as e:
                        with self.lock:
                            if self.error is None:
                                self.error = e
                        if log_callback:
                            log_callback(f"Thread {worker_id} error: {e}")
                        raise
                    finally:
                        work_queue.task_done()
                        
            except Exception as e:
                with self.lock:
                    if self.error is None:
                        self.error = e
        
        # Start worker threads
        threads = []
        for i in range(self.num_threads):
            t = threading.Thread(target=worker, args=(i,))
            t.start()
            threads.append(t)
        
        # Wait for all threads to complete
        for t in threads:
            t.join()
        
        # Check for errors
        if self.error:
            # Clean up temp files
            for temp_file in temp_files.values():
                if os.path.exists(temp_file):
                    os.remove(temp_file)
            raise self.error
        
        # Merge temporary files into final output
        if log_callback:
            log_callback("Merging downloaded segments...")
        
        mode = 'ab' if start_offset > 0 else 'wb'
        with open(output_file, mode) as outf:
            for thread_id in sorted(temp_files.keys()):
                temp_file = temp_files[thread_id]
                if os.path.exists(temp_file):
                    with open(temp_file, 'rb') as inf:
                        outf.write(inf.read())
                    os.remove(temp_file)
        
        return True


class SimpleParallelDownloader:
    """Simpler parallel downloader that works with streaming responses."""
    
    def __init__(self, num_connections: int = 4):
        """
        Initialize simple parallel downloader.
        
        Args:
            num_connections: Number of parallel connections (default: 4)
        """
        self.num_connections = num_connections
        self.lock = threading.Lock()
        self.downloaded = 0
    
    def download_range(self, 
                       download_func: Callable[[int], bytes],
                       output_file: str,
                       start: int,
                       end: int,
                       position: int,
                       pbar: Optional[tqdm] = None) -> None:
        """
        Download a specific range and write to file at position.
        
        Args:
            download_func: Function that takes start_byte and returns response
            output_file: Path to output file
            start: Start byte
            end: End byte (exclusive)
            position: File position to write to
            pbar: Optional progress bar
        """
        response = download_func(start)
        
        with open(output_file, 'r+b') as f:
            f.seek(position)
            bytes_to_read = end - start
            bytes_read = 0
            
            for chunk in response.iter_content(chunk_size=8*1024*1024):
                if chunk:
                    chunk_to_write = chunk[:bytes_to_read - bytes_read]
                    f.write(chunk_to_write)
                    bytes_read += len(chunk_to_write)
                    
                    if pbar:
                        with self.lock:
                            pbar.update(len(chunk_to_write))
                            self.downloaded += len(chunk_to_write)
                    
                    if bytes_read >= bytes_to_read:
                        break
